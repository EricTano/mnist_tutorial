{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a popular deep learning framework and it's easy to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation\n",
    "from keras.utils import np_utils\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 10\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the mnist data and preprocess them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and load the data (split them between train and test sets)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "# expand the channel dimension\n",
    "X_train = X_train.reshape(len(X_train), -1)\n",
    "X_test = X_test.reshape(len(X_test), -1)\n",
    "\n",
    "# make the value of pixels from [0, 255] to [0, 1] for further process\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = (X_train - 127) / 127\n",
    "X_test = (X_test - 127) / 127\n",
    "\n",
    "# convert class vectors to binary class matrics\n",
    "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the model, object function and optimizer that we use to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_shape=(784,), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5)) \n",
    "\n",
    "model.add(Dense(512, kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5)) \n",
    "\n",
    "model.add(Dense(NUM_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can start to train and evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57000 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "57000/57000 [==============================] - 15s 272us/step - loss: 0.5864 - acc: 0.8161 - val_loss: 0.1917 - val_acc: 0.9487\n",
      "Epoch 2/20\n",
      "57000/57000 [==============================] - 16s 278us/step - loss: 0.3574 - acc: 0.8908 - val_loss: 0.1350 - val_acc: 0.9613\n",
      "Epoch 3/20\n",
      "57000/57000 [==============================] - 15s 271us/step - loss: 0.3082 - acc: 0.9065 - val_loss: 0.1376 - val_acc: 0.9657\n",
      "Epoch 4/20\n",
      "57000/57000 [==============================] - 14s 251us/step - loss: 0.2757 - acc: 0.9170 - val_loss: 0.1204 - val_acc: 0.9713\n",
      "Epoch 5/20\n",
      "57000/57000 [==============================] - 14s 242us/step - loss: 0.2613 - acc: 0.9210 - val_loss: 0.1099 - val_acc: 0.9743\n",
      "Epoch 6/20\n",
      "57000/57000 [==============================] - 14s 248us/step - loss: 0.2495 - acc: 0.9243 - val_loss: 0.0969 - val_acc: 0.9747\n",
      "Epoch 7/20\n",
      "57000/57000 [==============================] - 16s 275us/step - loss: 0.2326 - acc: 0.9292 - val_loss: 0.0944 - val_acc: 0.9773\n",
      "Epoch 8/20\n",
      "57000/57000 [==============================] - 15s 261us/step - loss: 0.2218 - acc: 0.9328 - val_loss: 0.0925 - val_acc: 0.9810\n",
      "Epoch 9/20\n",
      "57000/57000 [==============================] - 16s 283us/step - loss: 0.2142 - acc: 0.9346 - val_loss: 0.0903 - val_acc: 0.9787\n",
      "Epoch 10/20\n",
      "57000/57000 [==============================] - 15s 267us/step - loss: 0.2151 - acc: 0.9362 - val_loss: 0.0944 - val_acc: 0.9797\n",
      "Epoch 11/20\n",
      "57000/57000 [==============================] - 15s 267us/step - loss: 0.2035 - acc: 0.9381 - val_loss: 0.0906 - val_acc: 0.9783\n",
      "Epoch 12/20\n",
      "57000/57000 [==============================] - 16s 280us/step - loss: 0.2007 - acc: 0.9399 - val_loss: 0.0800 - val_acc: 0.9823\n",
      "Epoch 13/20\n",
      "57000/57000 [==============================] - 16s 279us/step - loss: 0.1993 - acc: 0.9402 - val_loss: 0.0975 - val_acc: 0.9753\n",
      "Epoch 14/20\n",
      "57000/57000 [==============================] - 15s 267us/step - loss: 0.1946 - acc: 0.9432 - val_loss: 0.0837 - val_acc: 0.9797\n",
      "Epoch 15/20\n",
      "57000/57000 [==============================] - 16s 272us/step - loss: 0.1944 - acc: 0.9421 - val_loss: 0.0847 - val_acc: 0.9807\n",
      "Epoch 16/20\n",
      "57000/57000 [==============================] - 14s 248us/step - loss: 0.1835 - acc: 0.9449 - val_loss: 0.0858 - val_acc: 0.9800\n",
      "Epoch 17/20\n",
      "57000/57000 [==============================] - 14s 248us/step - loss: 0.1881 - acc: 0.9448 - val_loss: 0.0803 - val_acc: 0.9803\n",
      "Epoch 18/20\n",
      "57000/57000 [==============================] - 16s 277us/step - loss: 0.1868 - acc: 0.9442 - val_loss: 0.0842 - val_acc: 0.9793\n",
      "Epoch 19/20\n",
      "57000/57000 [==============================] - 15s 259us/step - loss: 0.1769 - acc: 0.9472 - val_loss: 0.0797 - val_acc: 0.9803\n",
      "Epoch 20/20\n",
      "57000/57000 [==============================] - 16s 280us/step - loss: 0.1793 - acc: 0.9482 - val_loss: 0.0760 - val_acc: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a9391f4dd8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=64, verbose=1, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6:\n",
    "Please print the training and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 65us/step\n",
      "Training loss: 0.0794, Training accuracy: 97.87%\n",
      "10000/10000 [==============================] - 1s 68us/step\n",
      "Training loss: 0.1072, Training accuracy: 96.90%\n"
     ]
    }
   ],
   "source": [
    "score_train = model.evaluate(X_train, y_train)\n",
    "print('Training loss: %.4f, Training accuracy: %.2f%%' % (score_train[0],100*score_train[1]))\n",
    "score_test = model.evaluate(X_test, y_test)\n",
    "print('Training loss: %.4f, Training accuracy: %.2f%%' % (score_test[0],100*score_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
